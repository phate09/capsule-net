{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CodeCell': {'cm_config': {'autoCloseBrackets': False}},\n",
       " 'Cell': {'cm_config': {'lineNumbers': True}}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from notebook.services.config import ConfigManager\n",
    "c = ConfigManager()\n",
    "c.update('notebook', {\"CodeCell\": {\"cm_config\": {\"autoCloseBrackets\": False}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plnn.mnist_sequential import Net\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_domain(input_tensor, eps_size):\n",
    "    return torch.stack((input_tensor - eps_size, input_tensor + eps_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('save/mnist_sequential_cnn.pt'))\n",
    "model.cuda()\n",
    "dataset = MNIST('./data', train=True, download=True,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                ])),  # load the testing dataset\n",
    "batch_size=10\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset, batch_size=1)#retrieve items 1 at a time\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationNetwork(nn.Module):\n",
    "    def __init__(self, in_features, out_features, base_network, out_function, true_class_index):\n",
    "        super(VerificationNetwork, self).__init__()\n",
    "        self.true_class_index = true_class_index\n",
    "        self.out_function = out_function\n",
    "        self.base_network = base_network\n",
    "        self.out_features = out_features\n",
    "        self.in_features = in_features\n",
    "        self.property_layer = self.attach_property_layers(self.base_network, self.true_class_index)\n",
    "\n",
    "    '''need to  repeat this method for each class so that it describes the distance between the corresponding class \n",
    "    and the closest other class'''\n",
    "    def attach_property_layers(self, model: Net, true_class_index: int):\n",
    "        n_classes = model.fc2.out_features\n",
    "        cases = []\n",
    "        for i in range(n_classes):\n",
    "            if i == true_class_index:\n",
    "                continue\n",
    "            case = [0] * n_classes  # list of zeroes\n",
    "            case[true_class_index] = 1  # sets the property to 1\n",
    "            case[i] = -1\n",
    "            cases.append(case)\n",
    "        weights = np.array(cases)\n",
    "        weightTensor = nn.Linear(in_features=n_classes, out_features=n_classes,\n",
    "                                 bias=False)\n",
    "        weightTensor.weight.data = torch.from_numpy(weights).float()\n",
    "        return weightTensor\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_network(x)\n",
    "        x = self.property_layer(x)\n",
    "        print(x)\n",
    "        print(x.size())\n",
    "        return torch.min(x,dim=1,keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size:torch.Size([10, 1, 28, 28])\n",
      "domain size:torch.Size([2, 10, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#get the data and label\n",
    "data, target =next(iter(test_loader))\n",
    "print(f'data size:{data.size()}')\n",
    "# print(data[0])\n",
    "# create the domain\n",
    "domain_raw = generate_domain(data,0.001)\n",
    "data_size=data.size()\n",
    "print(f'domain size:{domain_raw.size()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "test_out=model(data.cuda())\n",
    "print(test_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 784])\n"
     ]
    }
   ],
   "source": [
    "domain=domain_raw.view(2,batch_size,-1)\n",
    "print(domain.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_ub_point, global_ub = net.get_upper_bound(domain)\n",
    "# global_lb = net.get_lower_bound(domain)\n",
    "\n",
    "\n",
    "def get_upper_bound(domain):\n",
    "    #we try get_upper_bound\n",
    "    nb_samples = 1024\n",
    "    nb_inp = domain.size()[2:]  #get last dimensions\n",
    "    print(nb_inp)\n",
    "    # Not a great way of sampling but this will be good enough\n",
    "    # We want to get rows that are >= 0\n",
    "    rand_samples_size = [batch_size, nb_samples] + list(nb_inp)\n",
    "    print(rand_samples_size)\n",
    "    rand_samples = torch.zeros(rand_samples_size)\n",
    "    print(rand_samples.size())\n",
    "    # print(rand_samples)\n",
    "    rand_samples.uniform_(0, 1)\n",
    "    # print(rand_samples)\n",
    "    print(rand_samples.size())\n",
    "    domain_lb = domain.select(0, 0).contiguous()\n",
    "    domain_ub = domain.select(0, 1).contiguous()\n",
    "    # print(domain_lb)\n",
    "    print(domain_lb.size())\n",
    "    # print(domain_ub)\n",
    "    print(domain_ub.size())\n",
    "    domain_width = domain_ub - domain_lb\n",
    "    print(domain_width.size())\n",
    "    print(domain_lb.view([batch_size, 1] + list(nb_inp)).size())\n",
    "    print(domain_width.view([batch_size, 1] + list(nb_inp)).size())\n",
    "    domain_lb = domain_lb.view([batch_size, 1] + list(nb_inp)).expand(\n",
    "        [batch_size, nb_samples] + list(nb_inp))  #expand the initial point for the number of examples\n",
    "    print(domain_lb.size())\n",
    "    domain_width = domain_width.view([batch_size, 1] + list(nb_inp)).expand(\n",
    "        [batch_size, nb_samples] + list(nb_inp))  #expand the width for the number of examples\n",
    "    print(domain_width.size())\n",
    "    #those should be the same\n",
    "    print(domain_width.size())\n",
    "    print(rand_samples.size())\n",
    "    inps = domain_lb + domain_width * rand_samples\n",
    "    # print(inps) #each row shuld be different\n",
    "    print(inps.size())\n",
    "    #now flatten the first dimension into the second\n",
    "    flattened_size = [inps.size(0) * inps.size(1)] + list(inps.size()[2:])\n",
    "    print(flattened_size)\n",
    "    #rearrange the tensor so that is consumable by the model\n",
    "    print(data_size)\n",
    "    examples_data_size = [flattened_size[0]] + list(data_size[1:])  #the expected dimension of the example tensor\n",
    "    print(examples_data_size)\n",
    "    var_inps = torch.Tensor(inps).view(examples_data_size)\n",
    "    print(var_inps.size())  #should match data_size\n",
    "    print(inps.size())\n",
    "    # print(inps[0][0])\n",
    "    # print(inps[0][1])\n",
    "    # print(var_inps[0][0])\n",
    "    # print(var_inps[1][0])\n",
    "    outs = model.forward(var_inps.cuda())  #gets the input for the values\n",
    "    print(outs.size())\n",
    "    print(outs[0])  #those two should be very similar but different because they belong to two different random examples\n",
    "    print(outs[1])\n",
    "    print(target.unsqueeze(1))\n",
    "    target_expanded = target.unsqueeze(1).expand(\n",
    "        [batch_size, nb_samples])  #generates nb_samples copies of the target vector, all rows should be the same\n",
    "    print(target_expanded.size())\n",
    "    print(target_expanded)\n",
    "    target_idxs = target_expanded.contiguous().view(\n",
    "        batch_size * nb_samples)  #contains a list of indices that tells which columns out of the 10 classes to pick\n",
    "    print(target_idxs.size())  #the first dimension should match\n",
    "    print(outs.size())\n",
    "    print(outs[target_idxs[0]].size())\n",
    "    outs_true_class = outs.gather(1, target_idxs.cuda().view(-1,\n",
    "                                                             1))  #we choose dimension 1 because it's the one we want to reduce\n",
    "    print(outs_true_class.size())\n",
    "    # print(outs[0])\n",
    "    # print(target_idxs[1])\n",
    "    # print(outs[1][0])#these two should be similar but different because they belong to different examples\n",
    "    # print(outs[0][0])\n",
    "    print(outs_true_class.size())\n",
    "    outs_true_class_resized = outs_true_class.view(batch_size, nb_samples)\n",
    "    print(outs_true_class_resized.size())  #resize outputs so that they each row is a different element of each batch\n",
    "    upper_bound, idx = torch.min(outs_true_class_resized,\n",
    "                                 dim=1)  #this returns the distance of the network output from the given class, it selects the class which is furthest from the current one\n",
    "    print(upper_bound.size())\n",
    "    print(idx.size())\n",
    "    print(idx)\n",
    "    print(upper_bound)\n",
    "    # rearranged_idx=idx.view(list(inps.size()[0:2]))\n",
    "    # print(rearranged_idx.size()) #rearranged idx contains the indexes of the minimum class for each example, for each element of the batch\n",
    "    print(f'idx size {idx.size()}')\n",
    "    print(f'inps size {inps.size()}')\n",
    "    print(idx[0])\n",
    "    # upper_bound = upper_bound[0]\n",
    "    unsqueezed_idx = idx.cuda().view(-1, 1)\n",
    "    print(f'single size {inps[0][unsqueezed_idx[0][0]][:].size()}')\n",
    "    print(f'single size {inps[1][unsqueezed_idx[1][0]][:].size()}')\n",
    "    print(f'single size {inps[2][unsqueezed_idx[2][0]][:].size()}')\n",
    "    ub_point = [inps[x][idx[x]][:].numpy() for x in range(idx.size()[0])]\n",
    "    ub_point = torch.tensor(ub_point)\n",
    "    print(\n",
    "        ub_point)  #ub_point represents the input that amongst all examples returns the minimum response for the appropriate class\n",
    "    print(ub_point.size())\n",
    "    # print(unsqueezed_idx.size())\n",
    "    # ub_point = torch.gather(inps.cuda(),1,unsqueezed_idx.cuda())#todo for some reason it doesn't want to work\n",
    "    # print(ub_point.size())\n",
    "    return ub_point, upper_bound\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#test the method\n",
    "get_upper_bound(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now try to do the lower bound\n",
    "import gurobipy as grb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input_domain: Tensor containing in each row the lower and upper bound\n",
    "              for the corresponding dimension\n",
    "'''\n",
    "lower_bounds = []\n",
    "upper_bounds = []\n",
    "gurobi_vars = []\n",
    "# These three are nested lists. Each of their elements will itself be a\n",
    "# list of the neurons after a layer.\n",
    "\n",
    "gurobi_model = grb.Model()\n",
    "gurobi_model.setParam('OutputFlag', False)\n",
    "gurobi_model.setParam('Threads', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 784])\n"
     ]
    }
   ],
   "source": [
    "input_domain=domain.select(1,0)#we use a single domain, not ready for parallelisation yet\n",
    "print(input_domain.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ub=-0.4232129752635956 lb=-0.42521294951438904\n"
     ]
    }
   ],
   "source": [
    "## Do the input layer, which is a special case\n",
    "inp_lb = []\n",
    "inp_ub = []\n",
    "inp_gurobi_vars = []\n",
    "# for dim in range(input_domain.size()[1]):\n",
    "dim=0\n",
    "ub=input_domain[1][dim]#check this value, it can be messed up\n",
    "lb=input_domain[0][dim]\n",
    "print(f'ub={ub} lb={lb}')\n",
    "assert ub>lb , \"ub should be greater that lb\"\n",
    "#     print(f'ub={ub} lb={lb}')\n",
    "v = gurobi_model.addVar(lb=lb, ub=ub, obj=0,\n",
    "                      vtype=grb.GRB.CONTINUOUS,\n",
    "                      name=f'inp_{dim}')\n",
    "inp_gurobi_vars.append(v)\n",
    "inp_lb.append(lb)\n",
    "inp_ub.append(ub)\n",
    "gurobi_model.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bounds.append(inp_lb)\n",
    "upper_bounds.append(inp_ub)\n",
    "gurobi_vars.append(inp_gurobi_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.4252)\n",
      "tensor(-0.4232)\n"
     ]
    }
   ],
   "source": [
    "print(lower_bounds[0][0])\n",
    "print(upper_bounds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias_ub=6.959481716156006 bias_lb=6.959481716156006\n",
      "coeff=0.015848033130168915 upper=-0.006707093212753534 lower=-0.006738788913935423\n",
      "ub=6.952774524688721 lb=6.946035861968994\n",
      "<gurobi.LinExpr: 6.959481716156006 + 0.015848033130168915 inp_0>\n"
     ]
    }
   ],
   "source": [
    "layer_idx = 1\n",
    "# for layer in model.layers:\n",
    "layer = model.layers[0]\n",
    "new_layer_lb = []\n",
    "new_layer_ub = []\n",
    "new_layer_gurobi_vars = []\n",
    "neuron_idx=0\n",
    "ub = layer.bias.data[neuron_idx]\n",
    "lb = layer.bias.data[neuron_idx]\n",
    "print(f'bias_ub={ub} bias_lb={lb}')\n",
    "lin_expr = layer.bias.data[neuron_idx].item() #adds the bias to the linear expression\n",
    "prev_neuron_idx = 0\n",
    "coeff = layer.weight.data[neuron_idx, prev_neuron_idx]#picks the weight between the two neurons\n",
    "print(f'coeff={coeff} upper={coeff*upper_bounds[-1][prev_neuron_idx]} lower={coeff*lower_bounds[-1][prev_neuron_idx]}')\n",
    "assert coeff*lower_bounds[-1][prev_neuron_idx]!=coeff*upper_bounds[-1][prev_neuron_idx]\n",
    "ub =ub+ coeff*upper_bounds[-1][prev_neuron_idx]#multiplies the ub\n",
    "lb =ub+ coeff*lower_bounds[-1][prev_neuron_idx]#multiplies the lb\n",
    "print(f'ub={ub} lb={lb}')\n",
    "assert ub!=lb\n",
    "lin_expr += coeff.item() * gurobi_vars[-1][prev_neuron_idx]#multiplies the unknown by the coefficient\n",
    "print(lin_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v=<gurobi.Var lay1_0>\n"
     ]
    }
   ],
   "source": [
    "v = gurobi_model.addVar(lb=lb, ub=ub, obj=0,\n",
    "                              vtype=grb.GRB.CONTINUOUS,\n",
    "                              name=f'lay{layer_idx}_{neuron_idx}')\n",
    "gurobi_model.addConstr(v == lin_expr)\n",
    "gurobi_model.update()\n",
    "print(f'v={v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gurobi status 2\n"
     ]
    }
   ],
   "source": [
    "gurobi_model.setObjective(v, grb.GRB.MINIMIZE)\n",
    "gurobi_model.optimize()\n",
    "print(f'gurobi status {gurobi_model.status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "ub=7.0670485496521 lb=7.0670485496521\n",
      "gurobi status 3\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "LP wasn't optimally solved",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0c7d54da7ead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mgurobi_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'gurobi status {gurobi_model.status}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mgurobi_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LP wasn't optimally solved\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m# We have computed a lower bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: LP wasn't optimally solved"
     ]
    }
   ],
   "source": [
    "## Do the other layers, computing for each of the neuron, its upper\n",
    "## bound and lower bound\n",
    "layer_idx = 1\n",
    "# for layer in model.layers:\n",
    "layer = model.layers[0]\n",
    "print( type(layer))\n",
    "new_layer_lb = []\n",
    "new_layer_ub = []\n",
    "new_layer_gurobi_vars = []\n",
    "if type(layer) is nn.Linear:\n",
    "    for neuron_idx in range(layer.weight.size(0)):\n",
    "        ub = layer.bias.data[neuron_idx]\n",
    "        lb = layer.bias.data[neuron_idx]\n",
    "        lin_expr = layer.bias.data[neuron_idx].item()\n",
    "        for prev_neuron_idx in range(layer.weight.size(1)):\n",
    "            coeff = layer.weight.data[neuron_idx, prev_neuron_idx]\n",
    "            if coeff >= 0:\n",
    "                ub += coeff*upper_bounds[-1][prev_neuron_idx]\n",
    "                lb += coeff*lower_bounds[-1][prev_neuron_idx]\n",
    "            else:\n",
    "                ub += coeff*lower_bounds[-1][prev_neuron_idx]\n",
    "                lb += coeff*upper_bounds[-1][prev_neuron_idx]\n",
    "            lin_expr += coeff.item() * gurobi_vars[-1][prev_neuron_idx]\n",
    "        v = gurobi_model.addVar(lb=lb, ub=ub, obj=0,\n",
    "                              vtype=grb.GRB.CONTINUOUS,\n",
    "                              name=f'lay{layer_idx}_{neuron_idx}')\n",
    "        print(f'ub={ub} lb={lb}')\n",
    "#         assert ub>lb, \"ub is not bigger than lb\"\n",
    "#         print(f'v={v} lin_expr={lin_expr}')\n",
    "        gurobi_model.addConstr(v == lin_expr)\n",
    "        gurobi_model.update()\n",
    "\n",
    "        gurobi_model.setObjective(v, grb.GRB.MINIMIZE)\n",
    "        gurobi_model.optimize()\n",
    "        print(f'gurobi status {gurobi_model.status}')\n",
    "        assert gurobi_model.status == 2, \"LP wasn't optimally solved\"\n",
    "        # We have computed a lower bound\n",
    "        lb = v.X\n",
    "        v.lb = lb\n",
    "\n",
    "        # Let's now compute an upper bound\n",
    "        gurobi_model.setObjective(v, grb.GRB.MAXIMIZE)\n",
    "        gurobi_model.update()\n",
    "        gurobi_model.reset()\n",
    "        gurobi_model.optimize()\n",
    "        assert gurobi_model.status == 2, \"LP wasn't optimally solved\"\n",
    "        ub = v.X\n",
    "        v.ub = ub\n",
    "\n",
    "        new_layer_lb.append(lb)\n",
    "        new_layer_ub.append(ub)\n",
    "        new_layer_gurobi_vars.append(v)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "elif type(layer) == nn.ReLU:\n",
    "    for neuron_idx, pre_var in enumerate(gurobi_vars[-1]):\n",
    "        pre_lb = lower_bounds[-1][neuron_idx]\n",
    "        pre_ub = upper_bounds[-1][neuron_idx]\n",
    "\n",
    "        v = gurobi_model.addVar(lb=max(0, pre_lb),\n",
    "                              ub=max(0, pre_ub),\n",
    "                              obj=0,\n",
    "                              vtype=grb.GRB.CONTINUOUS,\n",
    "                              name=f'ReLU{layer_idx}_{neuron_idx}')\n",
    "        if pre_lb >= 0 and pre_ub >= 0:\n",
    "            # The ReLU is always passing\n",
    "            gurobi_model.addConstr(v == pre_var)\n",
    "            lb = pre_lb\n",
    "            ub = pre_ub\n",
    "        elif pre_lb <= 0 and pre_ub <= 0:\n",
    "            lb = 0\n",
    "            ub = 0\n",
    "            # No need to add an additional constraint that v==0\n",
    "            # because this will be covered by the bounds we set on\n",
    "            # the value of v.\n",
    "        else:\n",
    "            lb = 0\n",
    "            ub = pre_ub\n",
    "            gurobi_model.addConstr(v >= pre_var)\n",
    "\n",
    "            slope = pre_ub / (pre_ub - pre_lb)\n",
    "            bias = - pre_lb * slope\n",
    "            gurobi_model.addConstr(v <= slope * pre_var + bias)\n",
    "\n",
    "        new_layer_lb.append(lb)\n",
    "        new_layer_ub.append(ub)\n",
    "        new_layer_gurobi_vars.append(v)\n",
    "elif type(layer) == nn.MaxPool1d:\n",
    "    assert layer.padding == 0, \"Non supported Maxpool option\"\n",
    "    assert layer.dilation == 1, \"Non supported MaxPool option\"\n",
    "    nb_pre = len(gurobi_vars[-1])\n",
    "    window_size = layer.kernel_size\n",
    "    stride = layer.stride\n",
    "\n",
    "    pre_start_idx = 0\n",
    "    pre_window_end = pre_start_idx + window_size\n",
    "\n",
    "    while pre_window_end <= nb_pre:\n",
    "        lb = max(lower_bounds[-1][pre_start_idx:pre_window_end])\n",
    "        ub = max(upper_bounds[-1][pre_start_idx:pre_window_end])\n",
    "\n",
    "        neuron_idx = pre_start_idx // stride\n",
    "\n",
    "        v = gurobi_model.addVar(lb=lb, ub=ub, obj=0, vtype=grb.GRB.CONTINUOUS,\n",
    "                              name=f'Maxpool{layer_idx}_{neuron_idx}')\n",
    "        all_pre_var = 0\n",
    "        for pre_var in gurobi_vars[-1][pre_start_idx:pre_window_end]:\n",
    "            gurobi_model.addConstr(v >= pre_var)\n",
    "            all_pre_var += pre_var\n",
    "        all_lb = sum(lower_bounds[-1][pre_start_idx:pre_window_end])\n",
    "        max_pre_lb = lb\n",
    "        gurobi_model.addConstr(all_pre_var >= v + all_lb - max_pre_lb)\n",
    "\n",
    "        pre_start_idx += stride\n",
    "        pre_window_end = pre_start_idx + window_size\n",
    "\n",
    "        new_layer_lb.append(lb)\n",
    "        new_layer_ub.append(ub)\n",
    "        new_layer_gurobi_vars.append(v)\n",
    "elif type(layer) == View:\n",
    "#     continue\n",
    "    print(type(layer))\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "lower_bounds.append(new_layer_lb)\n",
    "upper_bounds.append(new_layer_ub)\n",
    "gurobi_vars.append(new_layer_gurobi_vars)\n",
    "\n",
    "layer_idx += 1\n",
    "\n",
    "# Assert that this is as expected a network with a single output\n",
    "assert len(gurobi_vars[-1]) == 1, \"Network doesn't have scalar output\"\n",
    "\n",
    "gurobi_model.update()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(data.size())\n",
    "true_class=torch.argmax(model(data.cuda()),dim=1)\n",
    "print(true_class.size())\n",
    "print(true_class)\n",
    "single_true_class=true_class[0].item()\n",
    "print(single_true_class)\n",
    "verification_model=VerificationNetwork(28,10,model,model.forward,single_true_class)\n",
    "verification_model.cuda()\n",
    "\n",
    "result=verification_model.forward(data.cuda())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
