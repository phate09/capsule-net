{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CodeCell': {'cm_config': {'autoCloseBrackets': False}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from notebook.services.config import ConfigManager\n",
    "c = ConfigManager()\n",
    "c.update('notebook', {\"CodeCell\": {\"cm_config\": {\"autoCloseBrackets\": False}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plnn.mnist_basic import Net\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_domain(input_tensor, eps_size):\n",
    "    return torch.stack((input_tensor - eps_size, input_tensor + eps_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('save/mnist_cnn.pt'))\n",
    "model.cuda()\n",
    "dataset = MNIST('./data', train=True, download=True,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                ])),  # load the testing dataset\n",
    "batch_size=10\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset, batch_size=1)#retrieve items 1 at a time\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationNetwork(nn.Module):\n",
    "    def __init__(self, in_features, out_features, base_network, out_function, true_class_index):\n",
    "        super(VerificationNetwork, self).__init__()\n",
    "        self.true_class_index = true_class_index\n",
    "        self.out_function = out_function\n",
    "        self.base_network = base_network\n",
    "        self.out_features = out_features\n",
    "        self.in_features = in_features\n",
    "        self.property_layer = self.attach_property_layers(self.base_network, self.true_class_index)\n",
    "\n",
    "    '''need to  repeat this method for each class so that it describes the distance between the corresponding class \n",
    "    and the closest other class'''\n",
    "    def attach_property_layers(self, model: Net, true_class_index: int):\n",
    "        n_classes = model.fc2.out_features\n",
    "        cases = []\n",
    "        for i in range(n_classes):\n",
    "            if i == true_class_index:\n",
    "                continue\n",
    "            case = [0] * n_classes  # list of zeroes\n",
    "            case[true_class_index] = 1  # sets the property to 1\n",
    "            case[i] = -1\n",
    "            cases.append(case)\n",
    "        weights = np.array(cases)\n",
    "        weightTensor = nn.Linear(in_features=n_classes, out_features=n_classes,\n",
    "                                 bias=False)\n",
    "        weightTensor.weight.data = torch.from_numpy(weights).float()\n",
    "        return weightTensor\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_network(x)\n",
    "        x = self.property_layer(x)\n",
    "        print(x)\n",
    "        print(x.size())\n",
    "        return torch.min(x,dim=1,keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size:torch.Size([10, 1, 28, 28])\ndomain size:torch.Size([2, 10, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#get the data and label\n",
    "data, target =next(iter(test_loader))\n",
    "print(f'data size:{data.size()}')\n",
    "# print(data[0])\n",
    "# create the domain\n",
    "domain_raw = generate_domain(data,0.001)\n",
    "data_size=data.size()\n",
    "print(f'domain size:{domain_raw.size()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "test_out=model(data.cuda())\n",
    "print(test_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 784])\n"
     ]
    }
   ],
   "source": [
    "domain=domain_raw.view(2,batch_size,-1)\n",
    "print(domain.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_ub_point, global_ub = net.get_upper_bound(domain)\n",
    "# global_lb = net.get_lower_bound(domain)\n",
    "\n",
    "\n",
    "def get_upper_bound(domain):\n",
    "    #we try get_upper_bound\n",
    "    nb_samples = 1024\n",
    "    nb_inp = domain.size()[2:]  #get last dimensions\n",
    "    print(nb_inp)\n",
    "    # Not a great way of sampling but this will be good enough\n",
    "    # We want to get rows that are >= 0\n",
    "    rand_samples_size = [batch_size, nb_samples] + list(nb_inp)\n",
    "    print(rand_samples_size)\n",
    "    rand_samples = torch.zeros(rand_samples_size)\n",
    "    print(rand_samples.size())\n",
    "    # print(rand_samples)\n",
    "    rand_samples.uniform_(0, 1)\n",
    "    # print(rand_samples)\n",
    "    print(rand_samples.size())\n",
    "    domain_lb = domain.select(0, 0).contiguous()\n",
    "    domain_ub = domain.select(0, 1).contiguous()\n",
    "    # print(domain_lb)\n",
    "    print(domain_lb.size())\n",
    "    # print(domain_ub)\n",
    "    print(domain_ub.size())\n",
    "    domain_width = domain_ub - domain_lb\n",
    "    print(domain_width.size())\n",
    "    print(domain_lb.view([batch_size, 1] + list(nb_inp)).size())\n",
    "    print(domain_width.view([batch_size, 1] + list(nb_inp)).size())\n",
    "    domain_lb = domain_lb.view([batch_size, 1] + list(nb_inp)).expand(\n",
    "        [batch_size, nb_samples] + list(nb_inp))  #expand the initial point for the number of examples\n",
    "    print(domain_lb.size())\n",
    "    domain_width = domain_width.view([batch_size, 1] + list(nb_inp)).expand(\n",
    "        [batch_size, nb_samples] + list(nb_inp))  #expand the width for the number of examples\n",
    "    print(domain_width.size())\n",
    "    #those should be the same\n",
    "    print(domain_width.size())\n",
    "    print(rand_samples.size())\n",
    "    inps = domain_lb + domain_width * rand_samples\n",
    "    # print(inps) #each row shuld be different\n",
    "    print(inps.size())\n",
    "    #now flatten the first dimension into the second\n",
    "    flattened_size = [inps.size(0) * inps.size(1)] + list(inps.size()[2:])\n",
    "    print(flattened_size)\n",
    "    #rearrange the tensor so that is consumable by the model\n",
    "    print(data_size)\n",
    "    examples_data_size = [flattened_size[0]] + list(data_size[1:])  #the expected dimension of the example tensor\n",
    "    print(examples_data_size)\n",
    "    var_inps = torch.Tensor(inps).view(examples_data_size)\n",
    "    print(var_inps.size())  #should match data_size\n",
    "    print(inps.size())\n",
    "    # print(inps[0][0])\n",
    "    # print(inps[0][1])\n",
    "    # print(var_inps[0][0])\n",
    "    # print(var_inps[1][0])\n",
    "    outs = model.forward(var_inps.cuda())  #gets the input for the values\n",
    "    print(outs.size())\n",
    "    print(outs[0])  #those two should be very similar but different because they belong to two different random examples\n",
    "    print(outs[1])\n",
    "    print(target.unsqueeze(1))\n",
    "    target_expanded = target.unsqueeze(1).expand(\n",
    "        [batch_size, nb_samples])  #generates nb_samples copies of the target vector, all rows should be the same\n",
    "    print(target_expanded.size())\n",
    "    print(target_expanded)\n",
    "    target_idxs = target_expanded.contiguous().view(\n",
    "        batch_size * nb_samples)  #contains a list of indices that tells which columns out of the 10 classes to pick\n",
    "    print(target_idxs.size())  #the first dimension should match\n",
    "    print(outs.size())\n",
    "    print(outs[target_idxs[0]].size())\n",
    "    outs_true_class = outs.gather(1, target_idxs.cuda().view(-1,\n",
    "                                                             1))  #we choose dimension 1 because it's the one we want to reduce\n",
    "    print(outs_true_class.size())\n",
    "    # print(outs[0])\n",
    "    # print(target_idxs[1])\n",
    "    # print(outs[1][0])#these two should be similar but different because they belong to different examples\n",
    "    # print(outs[0][0])\n",
    "    print(outs_true_class.size())\n",
    "    outs_true_class_resized = outs_true_class.view(batch_size, nb_samples)\n",
    "    print(outs_true_class_resized.size())  #resize outputs so that they each row is a different element of each batch\n",
    "    upper_bound, idx = torch.min(outs_true_class_resized,\n",
    "                                 dim=1)  #this returns the distance of the network output from the given class, it selects the class which is furthest from the current one\n",
    "    print(upper_bound.size())\n",
    "    print(idx.size())\n",
    "    print(idx)\n",
    "    print(upper_bound)\n",
    "    # rearranged_idx=idx.view(list(inps.size()[0:2]))\n",
    "    # print(rearranged_idx.size()) #rearranged idx contains the indexes of the minimum class for each example, for each element of the batch\n",
    "    print(f'idx size {idx.size()}')\n",
    "    print(f'inps size {inps.size()}')\n",
    "    print(idx[0])\n",
    "    # upper_bound = upper_bound[0]\n",
    "    unsqueezed_idx = idx.cuda().view(-1, 1)\n",
    "    print(f'single size {inps[0][unsqueezed_idx[0][0]][:].size()}')\n",
    "    print(f'single size {inps[1][unsqueezed_idx[1][0]][:].size()}')\n",
    "    print(f'single size {inps[2][unsqueezed_idx[2][0]][:].size()}')\n",
    "    ub_point = [inps[x][idx[x]][:].numpy() for x in range(idx.size()[0])]\n",
    "    ub_point = torch.tensor(ub_point)\n",
    "    print(\n",
    "        ub_point)  #ub_point represents the input that amongst all examples returns the minimum response for the appropriate class\n",
    "    print(ub_point.size())\n",
    "    # print(unsqueezed_idx.size())\n",
    "    # ub_point = torch.gather(inps.cuda(),1,unsqueezed_idx.cuda())#todo for some reason it doesn't want to work\n",
    "    # print(ub_point.size())\n",
    "    return ub_point, upper_bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784])\n[10, 1024, 784]\ntorch.Size([10, 1024, 784])\ntorch.Size([10, 1024, 784])\ntorch.Size([10, 784])\ntorch.Size([10, 784])\ntorch.Size([10, 784])\ntorch.Size([10, 1, 784])\ntorch.Size([10, 1, 784])\ntorch.Size([10, 1024, 784])\ntorch.Size([10, 1024, 784])\ntorch.Size([10, 1024, 784])\ntorch.Size([10, 1024, 784])\ntorch.Size([10, 1024, 784])\n[10240, 784]\ntorch.Size([10, 1, 28, 28])\n[10240, 1, 28, 28]\ntorch.Size([10240, 1, 28, 28])\ntorch.Size([10, 1024, 784])\ntorch.Size([10240, 10])\ntensor([-1.6408e+01, -1.5530e+01, -1.2936e+01, -9.0587e+00, -2.0639e+01,\n        -1.8038e+01, -3.0886e+01, -1.2112e-04, -1.4305e+01, -1.3569e+01],\n       device='cuda:0', grad_fn=<SelectBackward>)\ntensor([-1.6407e+01, -1.5529e+01, -1.2936e+01, -9.0581e+00, -2.0639e+01,\n        -1.8038e+01, -3.0886e+01, -1.2112e-04, -1.4304e+01, -1.3568e+01],\n       device='cuda:0', grad_fn=<SelectBackward>)\ntensor([[7],\n        [2],\n        [1],\n        [0],\n        [4],\n        [1],\n        [4],\n        [9],\n        [5],\n        [9]])\ntorch.Size([10, 1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 7, 7,  ..., 7, 7, 7],\n        [2, 2, 2,  ..., 2, 2, 2],\n        [1, 1, 1,  ..., 1, 1, 1],\n        ...,\n        [9, 9, 9,  ..., 9, 9, 9],\n        [5, 5, 5,  ..., 5, 5, 5],\n        [9, 9, 9,  ..., 9, 9, 9]])\ntorch.Size([10240])\ntorch.Size([10240, 10])\ntorch.Size([10])\ntorch.Size([10240, 1])\ntorch.Size([10240, 1])\ntorch.Size([10, 1024])\ntorch.Size([10])\ntorch.Size([10])\ntensor([  0,   0, 570,   0,  48, 724, 827, 624,  23,  96], device='cuda:0')\ntensor([-1.2112e-04,  0.0000e+00, -3.4809e-04, -3.0518e-05, -1.7262e-04,\n        -1.3924e-04, -3.4504e-03, -6.1989e-04, -4.0483e-03, -1.1921e-04],\n       device='cuda:0', grad_fn=<MinBackward0>)\nidx size torch.Size([10])\ninps size torch.Size([10, 1024, 784])\ntensor(0, device='cuda:0')\nsingle size torch.Size([784])\nsingle size torch.Size([784])\nsingle size torch.Size([784])\ntensor([[-0.4248, -0.4245, -0.4237,  ..., -0.4246, -0.4240, -0.4233],\n        [-0.4237, -0.4250, -0.4249,  ..., -0.4247, -0.4239, -0.4235],\n        [-0.4251, -0.4240, -0.4234,  ..., -0.4233, -0.4243, -0.4238],\n        ...,\n        [-0.4248, -0.4237, -0.4237,  ..., -0.4246, -0.4235, -0.4233],\n        [-0.4234, -0.4244, -0.4246,  ..., -0.4245, -0.4244, -0.4251],\n        [-0.4245, -0.4237, -0.4239,  ..., -0.4249, -0.4236, -0.4249]])\ntorch.Size([10, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4248, -0.4245, -0.4237,  ..., -0.4246, -0.4240, -0.4233],\n         [-0.4237, -0.4250, -0.4249,  ..., -0.4247, -0.4239, -0.4235],\n         [-0.4251, -0.4240, -0.4234,  ..., -0.4233, -0.4243, -0.4238],\n         ...,\n         [-0.4248, -0.4237, -0.4237,  ..., -0.4246, -0.4235, -0.4233],\n         [-0.4234, -0.4244, -0.4246,  ..., -0.4245, -0.4244, -0.4251],\n         [-0.4245, -0.4237, -0.4239,  ..., -0.4249, -0.4236, -0.4249]]),\n tensor([-1.2112e-04,  0.0000e+00, -3.4809e-04, -3.0518e-05, -1.7262e-04,\n         -1.3924e-04, -3.4504e-03, -6.1989e-04, -4.0483e-03, -1.1921e-04],\n        device='cuda:0', grad_fn=<MinBackward0>))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the method\n",
    "get_upper_bound(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gurobipy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-97ec3e8e66ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#now try to do the lower bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgurobipy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgrb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gurobipy'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#now try to do the lower bound\n",
    "# import gurobipy as grb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28])\n",
      "torch.Size([10])\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], device='cuda:0')\n",
      "7\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'VerificationNetwork' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-a67be0a9b2ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msingle_true_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_true_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mverification_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVerificationNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msingle_true_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mverification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VerificationNetwork' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(data.size())\n",
    "true_class=torch.argmax(model(data.cuda()),dim=1)\n",
    "print(true_class.size())\n",
    "print(true_class)\n",
    "single_true_class=true_class[0].item()\n",
    "print(single_true_class)\n",
    "verification_model=VerificationNetwork(28,10,model,model.forward,single_true_class)\n",
    "verification_model.cuda()\n",
    "\n",
    "result=verification_model.forward(data.cuda())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
